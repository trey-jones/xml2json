#!/usr/bin/env python3

"""
xml2json.py  Convert XML to JSON or properly formatted JSON to XML

This is a rewrite of xml2json by Hay Kranen.
The JSON output from XML should be the same as his version.
The JSON to XML output has been adjusted to more accurately differentiate
attributes from elements.

The format required to convert JSON to XML is the same as the output of
the XML to JSON conversion.

These are other features:

Uses python3 ---> will not work under python2
Use standard json library.
Use argparse instead of optparse.
Incrementally parse files to use less resources and allow parsing of large
files.
Overall improved memory management.
Attempted to clarify options and function names.

Author: Trey Jones <github.com/trey-jones>
June 19, 2012

Docstring of the original xml2json:
Relies on ElementTree for the XML parsing.  This is based on
pesterfish.py but uses a different XML->JSON mapping.
The XML->JSON mapping is described at
http://www.xml.com/pub/a/2006/05/31/converting-between-xml-and-json.html

Rewritten to a command line utility by Hay Kranen < github.com/hay >

XML                              JSON
<e/>                             "e": null
<e>text</e>                      "e": "text"
<e name="value" />               "e": { "@name": "value" }
<e name="value">text</e>         "e": { "@name": "value", "#text": "text" }
<e> <a>text</a ><b>text</b> </e> "e": { "a": "text", "b": "text" }
<e> <a>text</a> <a>text</a> </e> "e": { "a": ["text", "text"] }
<e> text <a>text</a> </e>        "e": { "#text": "text", "a": "text" }

This is very similar to the mapping used for Yahoo Web Services
(http://developer.yahoo.com/common/json.html#xml).

This is a mess in that it is so unpredictable -- it requires lots of testing
(e.g. to see if values are lists or strings or dictionaries).  For use
in Python this could be vastly cleaner.  Think about whether the internal
form can be more self-consistent while maintaining good external characteristics
for the JSON.

Look at the Yahoo version closely to see how it works.  Maybe can adopt
that completely if it makes more sense...

R. White, 2006 November 6
"""

import xml.etree.cElementTree as ET
import json, argparse, tempfile
from os.path import getsize


##
#   Take an instance of iterparse and recursively iterate on each element.
#   Convert elements to Python dictionary
#
#   @param Element elem Pass the root of an xml document (start event) to parse the whole document.
#   @return tuple,2 (tag, Python dictionary of subelements and attributes as well as text and tail)
##
def elem_to_dict(elem):
    """
    Convert an instance of xml.etree.cElementTree.Element to
    a python dictionary.
    """

    global doc, parsed_elements

    tag = elem.tag.strip()
    tail = elem.tail
    text = elem.text
    attributes = elem.keys()

    parsed_elem = {}

    event = 'start'

    ##
    #   recursively parses subelements
    #   each time it returns an element has 'ended'
    #   so the next event will either start a new subelement
    #   or end this element
    #   TODO namespaces?
    ##
    while event == 'start':
        event, next_element = next(doc)
        if event == 'end':
            parsed_elements += 1
            next_element.clear()
            display_progress(parsed_elements)
            break

        sub_tag, contents = elem_to_dict(next_element)

        if not sub_tag in parsed_elem.keys():
            parsed_elem[sub_tag] = []

        parsed_elem[sub_tag].append(contents)

    ## all subelements parsed, add everything else
    if tail != None:
        tail = tail.strip()
        if tail != '':
            parsed_elem['tail'] = tail

    if text != None:
        text = text.strip()
        if text != '':
            parsed_elem['text'] = text

    for a in attributes:
        value = elem.get(a)

        if value != None:
            parsed_elem[a] = value

    ## all finished parsing the element, so let's get rid of the contents
    ## TODO make sure everything including root is getting cleared
    elem.clear()

    return (tag, parsed_elem)


def large_elem_to_dict(elem, container, temp_dir):
    global doc, parsed_elements

    tag = elem.tag.strip()
    tail = elem.tail
    text = elem.text
    attributes = elem.keys()

    subelements = {}
    subelement_order = []

    event = 'start'

    while event == 'start':
        event, next_element = next(doc)
        if event == 'end':
            parsed_elements += 1
            display_progress(parsed_elements)
            break

        if not next_element.tag in subelements:
            subelements[next_element.tag] = tempfile.SpooledTemporaryFile(max_size=10000000, dir=temp_dir)  # max size is 10M, buffering from python docs
            subelements[next_element.tag].write(utf_encode('['))  # cast to bytes to write binary
            subelement_order.append(next_element.tag)  # TODO make this better

        large_elem_to_dict(next_element, subelements[next_element.tag], temp_dir)

    container.write(utf_encode('{'))

    # ghetto json writing
    no_comma = True
    for tag_name in subelement_order:
        # leave the comma off the first subelement
        if not no_comma:
            container.write(utf_encode(','))
        else:
            no_comma = False

        container.write(utf_encode('"' + tag_name + '":'))  # replace with json.dump?
        iter_transfer(subelements[tag_name], container)
        container.seek(-1, 2)  # remove trailing comma - it takes 2 bytes here because? probably EOF from iter_transfer
        container.write(utf_encode(']'))

    string_values = {}
    string_value_order = []  # TODO make this better

    if text != None:
        text = text.strip()
        if text != '':
            string_values['text'] = text
            string_value_order.append('text')

    if tail != None:
        tail = tail.strip()
        if tail != '':
            string_values['tail'] = tail
            string_value_order.append('tail')

    for a in attributes:
        value = elem.get(a)
        if value != None:
            string_values[a] = value
            string_value_order.append(a)

    # no comma will be false if there were any subelements
    for key in string_value_order:
        if not no_comma:
            container.write(utf_encode(','))
        else:
            no_comma = False

        container.write(utf_encode('"' + key + '":"' + string_values[key] + '"'))

    elem.clear()
    container.write(utf_encode('},'))


def iter_transfer(from_obj, to_obj):
    from_obj.seek(0)
    while True:
        data = from_obj.read(50000)

        if len(data) < 1:
            break

        to_obj.write(data)


def utf_encode(data):
    return bytes(data, encoding='utf-8')


##
#   @param string file Path and filename of the xml document to be parsed.
#   @return string JSON string of XML file
#   TODO: see about writing JSON to file as it is parsed?
##
def xml_to_json(infile, outfile):
    """
    Convert a properly formatted XML file to a JSON string.
    """

    analyze_xml(infile)

    global doc
    doc = ET.iterparse(infile, events=('start', 'end'))

    event, elem = next(doc)

    if not is_large_file(infile):
        tag, parsed = elem_to_dict(elem)

        with open(outfile) as out:
            json.dump({tag: parsed}, out, separators=(',', ':'))

    else:
        with tempfile.TemporaryDirectory() as temp_dir:

            with open(outfile, 'w+b') as out:
                out.write(utf_encode('{"' + elem.tag + '":'))
                large_elem_to_dict(elem, out, temp_dir)

                # remove trailing comma  TODO make this more interesting
                out.seek(-1, 2)
                out.write(utf_encode('}'))


##
#   @param string file Path and filename of the json document to be parsed.
#   @return string XML string
##
def json_to_xml(infile, outfile):
    pass


def is_large_file(file):
    return getsize(file) > 100000000  # 100M approximately


def analyze_xml(file):
    print('Analyzing input file.')

    check = ET.iterparse(file, events=('start', 'end'))
    event, root = next(check)

    global parsed_elements
    parsed_elements = 0
    global total_elements
    total_elements = 0

    for event, elem in check:
        if event == 'end':
            total_elements += 1
            elem.clear()

    root.clear()

    print('Found XML with ' + str(total_elements) + ' total elements.')
    print('Beginning conversion...')


def display_progress(i):
    global total_elements
    if i % 100000 == 0:
        print('\r{} elements parsed of {}.'.format(i, total_elements), end='')


##
#   Execute!
##
def main():
    p = argparse.ArgumentParser(description='Convert a file from XML to JSON or JSON to XML.')
    p.add_argument('in_file', metavar='IN', type=str, help='Path to the file that will be parsed.')
    p.add_argument('out_file', metavar='OUT', type=str, help='File to write output.  Pass "console" to print to stdout')
    p.add_argument('-m', '--mode', help='"xml" or "json" - This determines the output.', default='json')

    args = vars(p.parse_args())

    if args['mode'] == 'json':
        xml_to_json(args['in_file'], args['out_file'])
    elif args['mode'] == 'xml':
        json_to_xml(args['in_file'], args['out_file'])
    else:
        raise Exception('Invalid mode.  Type "xml2json3 -h" for more information')


if __name__ == '__main__':
    main()
